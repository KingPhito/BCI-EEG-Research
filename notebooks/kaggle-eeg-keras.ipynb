{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"grfgFhsOv_O4"},"source":["# **EEG Model with Keras and Wandb**\n","This is a test project I am using to learn Keras for structured data. I am using data from a past Kaggle competition to train a model that can detect certain events from EEG brainwave data. The events would then trigger certain gestures in a prosthetic device for example, using BCI technology. My goal is to get perfect/near perfect predictions on the testing data. You can get more info on the contest/dataset [here](https://www.kaggle.com/c/grasp-and-lift-eeg-detection/)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S1S32XeQzYh9"},"source":["## **Install The Libraries**\n","First we install install all necessary Python libraries with pip."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"z0LXxf1231d1"},"outputs":[],"source":["%pip install scikit-learn\n","%pip install --upgrade keras\n","%pip install --upgrade tensorflow[and-cuda]\n","%pip install --upgrade pandas\n","%pip install --upgrade numpy\n","%pip install wandb\n","%pip install kaggle"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u6PUd-ug2jNC"},"source":["## **Kaggle Environment Setup**\n","You will need to upload your *kaggle.json*, set the permissions so the file can be read."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"f0UnRzaJWuBG"},"outputs":[],"source":["!chmod 600 ../kaggle.json"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VmBsLfY0OS39"},"source":["Then we set the Kaggle configuration directory to our current working directory, as an environment variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Zge9yawNW31i"},"outputs":[],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] = '../'"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1kZmR-eNASVQ"},"source":["Now we can download the data from the competition page, "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"pWytfHWCkA_C"},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -p ../data/kaggle-eeg/ -f train.zip"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OSj3R5FGNp8w"},"source":["and unzip it into the data directory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"fJja6QKfmt7D"},"outputs":[],"source":["!unzip ../data/kaggle-eeg/train.zip -d ../data/kaggle-eeg"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XcKFL0C3AnUD"},"source":["## **Data Processing**\n","First let's import all the libraries we need."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"TAtBsA0TAx5n"},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"d1ePPH8NS3ck"},"source":["#### **Pandas**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LqsEMWAJCtPu"},"source":["Next we specify the path of our training data. Then we're specifying the types of our features and labels, because otherwise pandas will use a lot of memory storing them. \n","\n","The training data is separated into files representing 12 test subjects and 8 series per subject. And the files with our labels have a suffix of `events` attached to them. \n","* The `load_one_series` function takes a specific series of a subject, and merges it with the labels from the corresponding `events` csv.\n","* The `get_merged_series` function takes the nth series(the function parameter) \n","from every subject, and merges them into one dataframe using the `load_one_series` function. We're going to use this for our validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"ZEYW4xziOqSq"},"outputs":[],"source":["path = '../data/kaggle-eeg/train'\n","\n","feature_types = {\n","    'Id': 'str', 'Fp1': 'int16', 'Fp2': 'int16', 'F7': 'int16', 'F3': 'int16', 'Fz': 'int16',\n","    'F4': 'int16', 'F8': 'int16', 'FC5': 'int16', 'FC1': 'int16', 'FC2': 'int16', 'FC6': 'int16',\n","    'T7': 'int16', 'C3': 'int16', 'Cz': 'int16', 'C4': 'int16', 'T8': 'int16', 'TP9': 'int16',\n","    'CP5': 'int16', 'CP1': 'int16', 'CP2': 'int16', 'CP6': 'int16', 'TP10': 'int16', 'P7': 'int16',\n","    'P3': 'int16', 'Pz': 'int16', 'P4': 'int16', 'P8': 'int16', 'PO9': 'int16', 'O1': 'int16',\n","    'Oz': 'int16', 'O2': 'int16', 'PO10': 'int16'\n","}\n","\n","label_types = {\n","    'Id': 'str', 'HandStart': 'int8', 'FirstDigitTouch': 'int8', 'LiftOff': 'int8', \n","    'Replace': 'int8', 'BothReleased': 'int8', 'BothStartLoadPhase': 'int8'\n","}\n","\n","def load_one_series(sj, sr):\n","  df = pd.read_csv(f'{path}/subj{sj}_series{sr}_data.csv', dtype=feature_types, encoding='utf8')\n","  labels = pd.read_csv(f'{path}/subj{sj}_series{sr}_events.csv', dtype=label_types)\n","  keys = labels.keys()\n","  for id in range(0, len(df.index)):\n","    df.loc[id, 'Labels'] = 'None'\n","    for col in keys:\n","      if labels.at[id, col] == 1:\n","        df.loc[id, 'Labels'] = col\n","        break\n","  return df\n","\n","def get_merged_series(sr):\n","  df = None\n","  lst = []\n","  for sj in range(1, 13):\n","    temp = load_one_series(sj, sr)\n","    lst.append(temp)\n","  df = pd.concat(lst)\n","  return df"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EMuGje4AFIel"},"source":["Creating the validation set will take some time as these files are quite large. Make some coffee =). But once it's done we can save it locally to load faster in the future. So you should only need to do this once.  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"yt_jygH1z6kD"},"outputs":[],"source":["valid = get_merged_series(8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"3_T7Qq8HggFc"},"outputs":[],"source":["valid.to_csv('../data/kaggle-eeg/valid.csv', index=False, float_format='%.4f')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7YWNPjXYEPm1"},"source":["Here we load in our validation data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"KU0KJJoJg_Yq"},"outputs":[],"source":["valid = pd.read_csv('../data/kaggle-eeg/valid.csv', encoding='utf8')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5WFg3jfKKIN0"},"source":["Then we generate our first training set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"u-7g1VyBJAxU"},"outputs":[],"source":["train = load_one_series(1, 1)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mRVdUjEYnR8G"},"source":["The following two lines just remove the `id` column from our dataframes since we don't need them."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"k8Hw7DfNmavY"},"outputs":[],"source":["train = train.drop(columns=['id'])\n","train['Labels'] = pd.Categorical(train['Labels'])\n","train['Labels'] = train['Labels'].astype('category').cat.codes\n","train_x = train.drop(columns=['Labels'])\n","train_y = train['Labels']\n","\n","valid = valid.drop(columns=['id'])\n","valid['Labels'] = pd.Categorical(valid['Labels'])\n","valid['Labels'] = valid['Labels'].astype('category').cat.codes\n","valid_x = valid.drop(columns=['Labels'])\n","valid_y = valid['Labels']"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hs9UXHoBsGVx"},"source":["We can check here to make sure our data is organized as expected."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":409,"status":"ok","timestamp":1590178519359,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"VONkhLnTpWT8","outputId":"efcde749-811c-4e83-dad0-f1ce15f325f2"},"outputs":[],"source":["train_x.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"unb8Q61t-OE8"},"outputs":[],"source":["valid_y.info()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4V1PII80TV62"},"source":["## **Training**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_c1Y6FDmXONd"},"source":["### **Wandb Logging**\n","First we're going to login to Wandb with our api key so that we can log the training. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","executionInfo":{"elapsed":1953,"status":"ok","timestamp":1590177048979,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"HT17aFKIZhU3","outputId":"648d8ffe-b8af-426b-cd13-2c8485a4fa12"},"outputs":[],"source":["!wandb login d754544ba90d0be7ea7009afb39a9225330e6be9"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZnHT5d7sQD5E"},"source":["Initialize Wandb and specify a project name to keep track of metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","executionInfo":{"elapsed":3948,"status":"ok","timestamp":1590177055643,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"EA-GduHoOV1k","outputId":"7ee58405-29af-4ada-fe2b-9402e4aad352"},"outputs":[],"source":["import wandb\n","from wandb.keras import WandbCallback\n","\n","wandb.init(project=\"kaggle-eeg-tf\", config={\"hyper\": \"parameter\"})"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZXdPEyThXapx"},"source":["### **Model**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense, Dropout, InputLayer, Normalization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.regularizers import l2"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ARZS6sugr-gt"},"source":["Now we can create our Keras model for training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"SLDhXu7cUuzr"},"outputs":[],"source":["model = Sequential(\n","  [\n","    InputLayer(input_shape=(train_x.shape[1],)),\n","    Normalization(),\n","    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    Dense(6, activation='linear', kernel_regularizer=l2(0.01))\n","  ]\n",")\n","\n","lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n","  0.003,\n","  decay_steps=train.shape[0] / 5000 * 1000,\n","  decay_rate=1,\n","  staircase=False\n",")\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'],\n","              run_eagerly=True)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Gw_Ee3SEkcYx"},"source":["### **Fitting**\n","Here we convert our training and validation data frames into tensor flow datasets. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_ds = tf.data.Dataset.from_tensor_slices((train_x.values, train_y.values)).shuffle(10000).batch(1000)\n","valid_ds = tf.data.Dataset.from_tensor_slices((valid_x.values, valid_y.values)).batch(1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"tH-brjPOrJb6"},"outputs":[],"source":["model.fit(train_ds, validation_data=valid_ds, epochs=10, steps_per_epoch=12, callbacks=[WandbCallback()])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for sr in range(1, 13):\n","  for sj in range(1, 9):\n","    if sr == 1 and sj == 1:\n","      continue\n","    temp = load_one_series(sj, sr)\n","    temp = temp.drop(columns=['id'])\n","    temp['Labels'] = pd.Categorical(temp['Labels'])\n","    temp['Labels'] = temp['Labels'].astype('category').cat.codes\n","    temp_x = temp.drop(columns=['Labels'])\n","    temp_y = temp['Labels']\n","    temp_ds = tf.data.Dataset.from_tensor_slices((temp_x.values, temp_y.values)).shuffle(10000).batch(1000)\n","    model.fit(temp_ds, validation_data=valid_ds, epochs=10, steps_per_epoch=12, callbacks=[WandbCallback()])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2K--Jt6182Ze"},"source":["## **Testing**\n","We're gonna download the testing data now from the Kaggle competition and unzip into the data directory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Mcw0qbEpqkjI"},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -f test.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"uF-4ZsA3Ia_C"},"outputs":[],"source":["!unzip ../data/kaggle-eeg/test.zip -d ../data/kaggle-eeg"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RDLUFWKonI0l"},"source":["Here we load the sample submission from the Kaggle competition. This gives us a pre-made dataframe and we just need to update column values with predictions from our model. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -f sample_submission.csv.zip"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip ../data/kaggle-eeg/sample_submission.csv.zip -d ../data/kaggle-eeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"MPndLKOSVOR5"},"outputs":[],"source":["sub = pd.read_csv('../data/kaggle-eeg/sample_submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":263,"status":"ok","timestamp":1590182742782,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"uPV2V3mHnPSH","outputId":"0d5eac3c-cf12-4cb8-8e18-5eaeab35d98b"},"outputs":[],"source":["sub.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VFNIfCiJ-Edc"},"source":["Here we create a dataframe in the same shape as the example submission on the competition page."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"u5Dic5uwJZS3"},"outputs":[],"source":["path = '../data/kaggle-eeg/test'\n","\n","def get_merged_tests():\n","  tests = None\n","  for sj in range(1, 13):\n","    for sr in range(9, 11):\n","      c_tests = pd.read_csv(f'{path}/subj{sj}_series{sr}_data.csv', dtype=feature_types)\n","      tests = c_tests if tests is None else tests.append(c_tests, ignore_index=True)\n","  return tests"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"pL6TXJ-Th65c"},"outputs":[],"source":["tests = get_merged_tests()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Og5BNjrQmsY4"},"outputs":[],"source":["tests = tests.drop(columns=['id'])\n","tests.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"FRJ4pf5BhH2b"},"outputs":[],"source":["model.load_weights('model-best.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"colab_type":"code","executionInfo":{"elapsed":377,"status":"ok","timestamp":1590291396493,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"Nt1SFkuWqn9q","outputId":"1ae1fe8d-f846-4590-cc16-3dfdee982c7d"},"outputs":[],"source":["out = tests.loc[[0], :]  \n","out.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":683},"colab_type":"code","executionInfo":{"elapsed":20236,"status":"error","timestamp":1590291332097,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"5qoR7dLqMbtI","outputId":"e7ce69f3-dab7-4943-d34f-399ed15132a5"},"outputs":[],"source":["np.argmax(model.predict(out.to_dict()), axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"dI8MZByMhTm-"},"outputs":[],"source":["classes = ['HandStart', 'FirstDigitTouch', 'LiftOff', 'Replace', 'BothReleased', 'BothStartLoadPhase']\n","for id in range(tests.shape[0]):\n","    pred = classes[model.predict(tests.loc[id])[1]]\n","    nl = '\\n'\n","    log = f\"Current pred: {pred}. Rows left to predict: {len(tests.index) - id}...{nl}\"\n","    print(log)\n","    for col in sub.keys():\n","      sub.at[id, col] = 1 if col == pred else 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"eMACdgjbpxTf"},"outputs":[],"source":["sub.to_csv('../data/kaggl-eeg/submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle competitions submit grasp-and-lift-eeg-detection -f ../data/kaggle-eeg/submission.csv -m \"Message\""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNJ8aQh8YOJPg7rgKkhVC82","name":"EEG Keras","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
