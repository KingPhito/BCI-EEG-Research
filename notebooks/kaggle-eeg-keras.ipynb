{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"grfgFhsOv_O4"},"source":["# **EEG Model with Keras and Wandb**\n","This is a test project I am using to learn Keras for structured data. I am using data from a past Kaggle competition to train a model that can detect certain events from EEG brainwave data. The events would then trigger certain gestures in a prosthetic device for example, using BCI technology. My goal is to get perfect/near perfect predictions on the testing data. You can get more info on the contest/dataset [here](https://www.kaggle.com/c/grasp-and-lift-eeg-detection/)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S1S32XeQzYh9"},"source":["## **Install The Libraries**\n","First we install install all necessary Python libraries with pip."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"z0LXxf1231d1"},"outputs":[],"source":["%pip install scikit-learn\n","%pip install --upgrade keras\n","%pip install --upgrade tensorflow[and-cuda]\n","%pip install --upgrade pandas\n","%pip install --upgrade numpy\n","%pip install wandb\n","%pip install kaggle"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u6PUd-ug2jNC"},"source":["## **Kaggle Environment Setup**\n","You will need to upload your *kaggle.json*, set the permissions so the file can be read."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"f0UnRzaJWuBG"},"outputs":[],"source":["!chmod 600 ../kaggle.json"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VmBsLfY0OS39"},"source":["Then we set the Kaggle configuration directory to our current working directory, as an environment variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Zge9yawNW31i"},"outputs":[],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] = '../'"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1kZmR-eNASVQ"},"source":["Now we can download the data from the competition page, "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"pWytfHWCkA_C"},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -p ../data/kaggle-eeg/ -f train.zip"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OSj3R5FGNp8w"},"source":["and unzip it into the data directory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"fJja6QKfmt7D"},"outputs":[],"source":["!unzip ../data/kaggle-eeg/train.zip -d ../data/kaggle-eeg"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XcKFL0C3AnUD"},"source":["## **Data Analysis**\n","First let's import all the libraries we need."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"TAtBsA0TAx5n"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import wandb\n","\n","from wandb.keras import WandbCallback\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.regularizers import l2"]},{"cell_type":"markdown","metadata":{},"source":["First we load some of the training data and check the first few rows."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"ZEYW4xziOqSq"},"outputs":[],"source":["data_path = '../data/kaggle-eeg/train'\n","features = pd.read_csv(f'{data_path}/subj1_series1_data.csv')\n","labels = pd.read_csv(f'{data_path}/subj1_series1_events.csv')\n","features = features.drop(columns=['id'])\n","labels = labels.drop(columns=['id'])\n","features.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labels.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4V1PII80TV62"},"source":["## **Training**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_c1Y6FDmXONd"},"source":["### **Wandb Logging**\n","First we're going to login to Wandb with our api key so that we can log the training. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","executionInfo":{"elapsed":1953,"status":"ok","timestamp":1590177048979,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"HT17aFKIZhU3","outputId":"648d8ffe-b8af-426b-cd13-2c8485a4fa12"},"outputs":[],"source":["!wandb login d754544ba90d0be7ea7009afb39a9225330e6be9"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZnHT5d7sQD5E"},"source":["Initialize Wandb and specify a project name to keep track of metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","executionInfo":{"elapsed":3948,"status":"ok","timestamp":1590177055643,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"EA-GduHoOV1k","outputId":"7ee58405-29af-4ada-fe2b-9402e4aad352"},"outputs":[],"source":["wandb.init(\n","    project=\"kaggle-eeg-tf\", \n","    config={\n","        \"hyper\": \"parameter\",\n","        \"epochs\": 17983756,\n","        \"batch_size\": 719350,\n","        \"loss_function\": \"categorical_crossentropy\",\n","        \"architecture\": \"CNN\",\n","        \"dataset\": \"kaggle-eeg\"\n","    }\n",")"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Gw_Ee3SEkcYx"},"source":["### **TF Data Loading**\n","Here we convert our training and validation data frames into tensor flow datasets. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_files = [f'{data_path}/{file}' for file in os.listdir(data_path)]\n","feature_files, label_files = [], []\n","\n","for i in range(len(train_files)):\n","  if i % 2 == 0:\n","    feature_files.append(train_files[i])\n","  else:\n","    label_files.append(train_files[i])\n","\n","batch_size = 719350\n","\n","def train_data_generator(feature_files, label_files, batch_size=1000):\n","  for i in range(len(feature_files)):\n","    with open(feature_files[i], 'r') as f1, open(label_files[i], 'r') as f2:\n","      feature_data = pd.read_csv(f1, encoding='utf8', chunksize=batch_size)\n","      label_data = pd.read_csv(f2, encoding='utf8', chunksize=batch_size)\n","      for feature_chunk, label_chunk in zip(feature_data, label_data):\n","        feature_chunk = feature_chunk.drop(['id'], axis=1)\n","        label_chunk = label_chunk.drop(['id'], axis=1)\n","        yield feature_chunk, label_chunk\n","\n","count = 17983756 * 0.8\n","\n","\n","ds = tf.data.Dataset.from_generator(\n","    train_data_generator,\n","    args=[feature_files, label_files],\n","    output_signature=(\n","        tf.TensorSpec(shape=(None, 32), dtype=tf.int16),\n","        tf.TensorSpec(shape=(None, 6), dtype=tf.int8)\n","    )\n",")\n","\n","ds.shuffle(17900000).padded_batch(batch_size, padded_shapes=([None, 32], [None, 6]))\n","train_ds = ds.take(int(count * 0.8))\n","valid_ds = ds.skip(int(count * 0.8))\n","print(train_ds.element_spec)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZXdPEyThXapx"},"source":["### **Model**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ARZS6sugr-gt"},"source":["Now we can create our Keras model for training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"SLDhXu7cUuzr"},"outputs":[],"source":["model = Sequential(\n","  [\n","    BatchNormalization(input_shape=(features.shape[1],)),\n","    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n","    Dropout(0.5),\n","    Dense(6)\n","  ], name='kaggle-eeg'\n",")\n","\n","lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n","  0.0001,\n","  decay_steps= count / batch_size * 1000,\n","  decay_rate=1,\n","  staircase=False\n",")\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'],\n","              run_eagerly=True)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"tH-brjPOrJb6"},"outputs":[],"source":["model.fit(train_ds, validation_data=valid_ds, epochs=17983756, steps_per_epoch=20, callbacks=[WandbCallback()])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.evaluate(valid_ds)"]},{"cell_type":"markdown","metadata":{},"source":["### **Training Loop**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2K--Jt6182Ze"},"source":["## **Testing**\n","We're gonna download the testing data now from the Kaggle competition and unzip into the data directory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Mcw0qbEpqkjI"},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -f test.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"uF-4ZsA3Ia_C"},"outputs":[],"source":["!unzip ../data/kaggle-eeg/test.zip -d ../data/kaggle-eeg"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RDLUFWKonI0l"},"source":["Here we load the sample submission from the Kaggle competition. This gives us a pre-made dataframe and we just need to update column values with predictions from our model. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -f sample_submission.csv.zip"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip ../data/kaggle-eeg/sample_submission.csv.zip -d ../data/kaggle-eeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"MPndLKOSVOR5"},"outputs":[],"source":["sub = pd.read_csv('../data/kaggle-eeg/sample_submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":263,"status":"ok","timestamp":1590182742782,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"uPV2V3mHnPSH","outputId":"0d5eac3c-cf12-4cb8-8e18-5eaeab35d98b"},"outputs":[],"source":["sub.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VFNIfCiJ-Edc"},"source":["Here we create a dataframe in the same shape as the example submission on the competition page."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"u5Dic5uwJZS3"},"outputs":[],"source":["path = '../data/kaggle-eeg/test'\n","\n","def get_merged_tests():\n","  tests = None\n","  for sj in range(1, 13):\n","    for sr in range(9, 11):\n","      c_tests = pd.read_csv(f'{path}/subj{sj}_series{sr}_data.csv')\n","      tests = c_tests if tests is None else tests.append(c_tests, ignore_index=True)\n","  return tests"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"pL6TXJ-Th65c"},"outputs":[],"source":["tests = get_merged_tests()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Og5BNjrQmsY4"},"outputs":[],"source":["tests = tests.drop(columns=['id'])\n","tests.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"FRJ4pf5BhH2b"},"outputs":[],"source":["model.load_weights('model-best.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"colab_type":"code","executionInfo":{"elapsed":377,"status":"ok","timestamp":1590291396493,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"Nt1SFkuWqn9q","outputId":"1ae1fe8d-f846-4590-cc16-3dfdee982c7d"},"outputs":[],"source":["out = tests.loc[[0], :]  \n","out.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"dI8MZByMhTm-"},"outputs":[],"source":["classes = ['HandStart', 'FirstDigitTouch', 'LiftOff', 'Replace', 'BothReleased', 'BothStartLoadPhase']\n","for id in range(tests.shape[0]):\n","    pred = model.predict(tests.loc[[id], :])\n","    tests.loc[[id], classes] = pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"eMACdgjbpxTf"},"outputs":[],"source":["sub.to_csv('../data/kaggl-eeg/submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle competitions submit grasp-and-lift-eeg-detection -f ../data/kaggle-eeg/submission.csv -m \"Message\""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNJ8aQh8YOJPg7rgKkhVC82","name":"EEG Keras","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
