{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"grfgFhsOv_O4"},"source":["# **Comparative Analysis of Tree Ensemble Models for EEG Event Detection**\n","\n","I am using data from a past Kaggle competition to train a model that can detect certain events from EEG brainwave data. The events would then trigger certain gestures in a prosthetic device for example, using BCI technology. My goal is to get perfect/near perfect predictions on the testing data. You can get more info on the contest/dataset [here](https://www.kaggle.com/c/grasp-and-lift-eeg-detection/)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S1S32XeQzYh9"},"source":["## **Install The Libraries**\n","First we install install all necessary Python libraries. Check the [README.md](../README.md) file for more info on how to do this."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u6PUd-ug2jNC"},"source":["## **Kaggle Environment Setup**\n","You will need to upload your *kaggle.json*, set the permissions so the file can be read."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"f0UnRzaJWuBG"},"outputs":[],"source":["!chmod 600 ../kaggle.json"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VmBsLfY0OS39"},"source":["Then we set the Kaggle configuration directory to our current working directory, as an environment variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Zge9yawNW31i"},"outputs":[],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] = '../'"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1kZmR-eNASVQ"},"source":["Now we can download the data from the competition page, "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"pWytfHWCkA_C"},"outputs":[],"source":["if not os.path.exists('../data/kaggle-eeg'):\n","    os.makedirs('../data/kaggle-eeg')\n","    !kaggle competitions download grasp-and-lift-eeg-detection -p ../data/kaggle-eeg/ -f train.zip\n","    !unzip ../data/kaggle-eeg/train.zip -d ../data/kaggle-eeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"TAtBsA0TAx5n"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from mne.decoding import CSP\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score, hamming_loss, jaccard_score, multilabel_confusion_matrix, classification_report, ConfusionMatrixDisplay\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n","import wandb\n","pd.set_option('display.max_columns', None)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XcKFL0C3AnUD"},"source":["## **Data Analysis**\n","First we load some of the training data and check the first few rows."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"ZEYW4xziOqSq"},"outputs":[],"source":["data_path = '../data/kaggle-eeg/train'\n","features = pd.read_csv(f'{data_path}/subj1_series1_data.csv')\n","labels = pd.read_csv(f'{data_path}/subj1_series1_events.csv')\n","features = features.drop(columns=['id'])\n","labels = labels.drop(columns=['id'])\n","\n","display(features.info(), features.describe(), features.head(), labels.info(), labels.describe(), labels.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["corr = features.corr()\n","plt.figure(figsize=(30, 20))\n","sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4V1PII80TV62"},"source":["## **Training**"]},{"cell_type":"markdown","metadata":{},"source":["### **Data Preprocessing**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_series_data(subject, series):\n","    features = pd.read_csv(f'{data_path}/subj{subject}_series{series}_data.csv')\n","    labels = pd.read_csv(f'{data_path}/subj{subject}_series{series}_events.csv')\n","    return features, labels\n","\n","def merge_labels(features, labels):\n","    data = features.copy()\n","    data = data.merge(labels, on='id')\n","    data.drop(columns=['id'], inplace=True)\n","    return data\n","\n","def get_training_batch(series):\n","    features, labels = load_series_data(1, series)\n","    data = merge_labels(features, labels)\n","    for i in range(2, 13):\n","        features, labels = load_series_data(i, series)\n","        data = pd.concat([data, merge_labels(features, labels)])\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df = get_training_batch(1)\n","train_df.shape, train_df.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_categories(data):\n","    label_counts = data[['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']].value_counts()\n","    categories = list(label_counts.index)\n","    category_dict = {category: i for i, category in enumerate(categories)}\n","    return category_dict\n","\n","category_dict = get_categories(train_df)\n","category_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# reshape data for CSP\n","def reshape_data(data, category_dict=category_dict):\n","    X = data.drop(columns=['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']).values\n","    y = data[['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']].values\n","    y = y.astype(np.float64)\n","    X = np.expand_dims(X, axis=2)\n","    X = X.astype(np.float64)\n","    return X, y\n","\n","X_train, y_train = reshape_data(train_df)\n","X_train = X_train.astype('float64').copy()\n","X_train.shape, y_train.shape, X_train.dtype, y_train.dtype"]},{"cell_type":"markdown","metadata":{},"source":["### **Model Building**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_model(pipeline, param_grid, X_train, y_train, outer_cv=5, inner_cv=5):\n","    outer_cv = KFold(n_splits=outer_cv, shuffle=True, random_state=42)\n","    scores = []\n","    best_estimators = [] # Store a list of best estimators for each label\n","    best_scores = [] # Store a list of best scores for each label\n","\n","    for train_index, test_index in outer_cv.split(X_train):\n","        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n","        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n","        \n","        # Initialize list to store best estimators and scores for each label in this outer fold\n","        fold_best_estimators = []\n","        fold_best_scores = []\n","\n","        # Iterate over each label (column) in the multi-label target matrix\n","        for label_idx in range(y_train_fold.shape[1]):\n","            y_train_label = y_train_fold[:, label_idx]\n","            y_test_label = y_test_fold[:, label_idx]\n","\n","            inner_cv = KFold(n_splits=inner_cv, shuffle=True, random_state=42)\n","            grid_search = GridSearchCV(pipeline, param_grid, cv=inner_cv, n_jobs=-1, verbose=1, scoring='accuracy') # You may change scoring to other suitable multi-label metrics\n","            grid_search.fit(X_train_fold, y_train_label)\n","\n","            y_pred = grid_search.predict(X_test_fold)\n","            \n","            # Example: Calculate multiple metrics\n","            accuracy = accuracy_score(y_test_label, y_pred)\n","            jaccard = jaccard_score(y_test_label, y_pred, average='samples')  \n","            hamming = hamming_loss(y_test_label, y_pred)\n","\n","            scores.append({'accuracy': accuracy, 'jaccard': jaccard, 'hamming': hamming}) \n","            fold_best_estimators.append(grid_search.best_estimator_)\n","            fold_best_scores.append(jaccard)  \n","\n","        best_estimators.append(fold_best_estimators)\n","        best_scores.append(fold_best_scores)\n","        \n","\n","    best_label_indices = []\n","    for scores_per_fold in best_scores:\n","        best_label_indices.append(np.argmax(scores_per_fold))\n","\n","    best_estimators_final = []\n","    for i in range(len(best_estimators)):  # Outer fold\n","        best_estimators_final.append(best_estimators[i][best_label_indices[i]])\n","\n","    return best_estimators_final, scores  # Return a list of best estimators, one per label\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Random Forest Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rf_clf = Pipeline([('CSP', CSP(n_components=4)),\n","                     ('RF', RandomForestClassifier())])\n","\n","param_grid = {\n","    'CSP__n_components': [2, 4, 6],\n","    'RF__n_estimators': [50, 100, 200],\n","    'RF__max_depth': [10, 20, 30]\n","}\n","\n","best_rf_clf, scores, best_rf_params = build_model(rf_clf, param_grid, X_train, y_train)\n","print(\"Grid search scores: \", scores)\n","rf_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","scores = cross_val_score(best_rf_clf, X_train, y_train, cv=rf_cv, scoring='accuracy')\n","print(\"Cross-validation scores: \", scores)"]},{"cell_type":"markdown","metadata":{},"source":["#### Gradient Boosting Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### XGBoost Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_c1Y6FDmXONd"},"source":["### **Wandb Logging**\n","First we're going to login to Wandb with our api key so that we can log the training. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","executionInfo":{"elapsed":1953,"status":"ok","timestamp":1590177048979,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"HT17aFKIZhU3","outputId":"648d8ffe-b8af-426b-cd13-2c8485a4fa12"},"outputs":[],"source":["!wandb login d754544ba90d0be7ea7009afb39a9225330e6be9"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZnHT5d7sQD5E"},"source":["Initialize Wandb and specify a project name to keep track of metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","executionInfo":{"elapsed":3948,"status":"ok","timestamp":1590177055643,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"EA-GduHoOV1k","outputId":"7ee58405-29af-4ada-fe2b-9402e4aad352"},"outputs":[],"source":["wandb.init(\n","    project=\"eeg-signal-classification\", \n","    config={\n","        \"hyper\": \"parameter\",\n","        \"epochs\": 17983756,\n","        \"batch_size\": 719350,\n","        \"loss_function\": \"categorical_crossentropy\",\n","        \"architecture\": \"CNN\",\n","        \"dataset\": \"kaggle-eeg\"\n","    }\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### **Training Loop**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def training_loop(model):\n","    total_test_x = pd.DataFrame()\n","    total_test_y = pd.DataFrame()\n","    for series in range(1, 9):\n","        train_df = get_training_batch(series)\n","        category_dict = get_categories(train_df)\n","        X_train, y_train = reshape_data(train_df, category_dict)\n","        train_x, test_x, train_y, test_y = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","        model.fit(train_x, train_y)\n","        total_test_x = pd.concat([total_test_x, test_x])\n","        total_test_y = pd.concat([total_test_y, test_y])\n","        score = accuracy_score(total_test_y, model.predict(total_test_x))\n","        wandb.log({\"series\": series, \"score\": score, \"model\": model.__qualname__()})\n","        print(f\"Series {series} score: {score}\")\n","    y_pred = model.predict(total_test_x)\n","    accuracy = accuracy_score(total_test_y, y_pred)\n","    report = classification_report(total_test_y, y_pred)\n","    return accuracy, report, multilabel_confusion_matrix(total_test_y, y_pred)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2K--Jt6182Ze"},"source":["## **Submission**\n","We're gonna download the testing data now from the Kaggle competition and unzip into the data directory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Mcw0qbEpqkjI"},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -f test.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"uF-4ZsA3Ia_C"},"outputs":[],"source":["!unzip ../data/kaggle-eeg/test.zip -d ../data/kaggle-eeg"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RDLUFWKonI0l"},"source":["Here we load the sample submission from the Kaggle competition. This gives us a pre-made dataframe and we just need to update column values with predictions from our model. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -f sample_submission.csv.zip"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip ../data/kaggle-eeg/sample_submission.csv.zip -d ../data/kaggle-eeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"MPndLKOSVOR5"},"outputs":[],"source":["sub = pd.read_csv('../data/kaggle-eeg/sample_submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":263,"status":"ok","timestamp":1590182742782,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"uPV2V3mHnPSH","outputId":"0d5eac3c-cf12-4cb8-8e18-5eaeab35d98b"},"outputs":[],"source":["sub.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VFNIfCiJ-Edc"},"source":["Here we create a dataframe in the same shape as the example submission on the competition page."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"u5Dic5uwJZS3"},"outputs":[],"source":["path = '../data/kaggle-eeg/test'\n","\n","def get_merged_tests():\n","  tests = None\n","  for sj in range(1, 13):\n","    for sr in range(9, 11):\n","      c_tests = pd.read_csv(f'{path}/subj{sj}_series{sr}_data.csv')\n","      tests = c_tests if tests is None else tests.append(c_tests, ignore_index=True)\n","  return tests"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"pL6TXJ-Th65c"},"outputs":[],"source":["tests = get_merged_tests()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Og5BNjrQmsY4"},"outputs":[],"source":["tests = tests.drop(columns=['id'])\n","tests.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"colab_type":"code","executionInfo":{"elapsed":377,"status":"ok","timestamp":1590291396493,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"Nt1SFkuWqn9q","outputId":"1ae1fe8d-f846-4590-cc16-3dfdee982c7d"},"outputs":[],"source":["out = tests.loc[[0], :]  \n","out.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"dI8MZByMhTm-"},"outputs":[],"source":["classes = ['HandStart', 'FirstDigitTouch', 'LiftOff', 'Replace', 'BothReleased', 'BothStartLoadPhase']\n","for id in range(tests.shape[0]):\n","    pred = model.predict(tests.loc[[id], :])\n","    tests.loc[[id], classes] = pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"eMACdgjbpxTf"},"outputs":[],"source":["sub.to_csv('../data/kaggl-eeg/submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle competitions submit grasp-and-lift-eeg-detection -f ../data/kaggle-eeg/submission.csv -m \"Message\""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNJ8aQh8YOJPg7rgKkhVC82","name":"EEG Keras","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
