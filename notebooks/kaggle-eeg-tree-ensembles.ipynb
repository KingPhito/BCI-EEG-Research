{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"grfgFhsOv_O4"},"source":["# **Comparative Analysis of Tree Ensemble Models for EEG Event Detection**\n","This notebook is a comparative analysis of tree ensemble models for EEG event detection. I will be evaluating the performance of the following models:\n","1. Random Forest\n","2. Gradient Boosting\n","3. XGBoost\n","\n","I will be using a simple pipeline to preprocess the data and train the models. The pipeline will consist of the following steps:\n","1. Feature extraction from the EEG channels Using Common Spatial Patterns (CSP).\n","2. Multi label classification using the tree ensemble models mentioned above.\n","\n","I will be performing a grid search for hyper-parameter tuning of each model, and then will also be using five fold cross validation to hopefully protect against overfitting.\n","I will compare the performance of the models using the following metrics:\n","1. Precision\n","2. Recall\n","3. F1 Score\n","4. Confusion Matrix\n","\n","I am using data from this [Grasp-and-Lift EEG Detection](https://www.kaggle.com/c/grasp-and-lift-eeg-detection/) competition. The data consists of EEG recordings from 32 channels for 10 subjects. The data is divided into 45 trials for each subject. Each trial consists of 6 events. The goal is to detect the start and end of each event in the EEG recordings. This competition is from 2015, but it serves as an excellent data set for benchmarking EEG event detection algorithms.This will also allow me to test the effectiveness of these models against all the submissions to this competition.\n","\n","I was inspired by the work being done at Stanford University on [NOIR: Neural Signal Operated Intelligent Robots](https://noir-corl.github.io/). They are using CSP And quadratic discriminate analysis(QDA) to process EEG signals, and have had amazing results with study participants being able to control robots. The data set I am working with here however is structured as a multi label classification problem, so I opted To compare the efficacy of tree ensembles in place of QDA. I believe that EEG signals have the potential to revolutionize human-computer interaction, especially for people with physical disabilities like myself. I hope that this notebook will inspire others to work on EEG event detection and other EEG applications."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S1S32XeQzYh9"},"source":["## **Install The Libraries**\n","First we install install all necessary Python libraries. Check the [README.md](../README.md) file for more info on how to do this."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u6PUd-ug2jNC"},"source":["## **Kaggle Environment Setup**\n","You will need to upload your *kaggle.json*, set the permissions so the file can be read."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"f0UnRzaJWuBG"},"outputs":[],"source":["!chmod 600 ../kaggle.json"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VmBsLfY0OS39"},"source":["Then we set the Kaggle configuration directory to our current working directory, as an environment variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Zge9yawNW31i"},"outputs":[],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] = '../'"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1kZmR-eNASVQ"},"source":["Now we can download the data from the competition page, "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"pWytfHWCkA_C"},"outputs":[],"source":["if not os.path.exists('../data/kaggle-eeg'):\n","    os.makedirs('../data/kaggle-eeg')\n","    !kaggle competitions download grasp-and-lift-eeg-detection -p ../data/kaggle-eeg/ -f train.zip\n","    !unzip ../data/kaggle-eeg/train.zip -d ../data/kaggle-eeg"]},{"cell_type":"markdown","metadata":{},"source":["## **Imports**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"TAtBsA0TAx5n"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from mne.decoding import CSP\n","from xgboost import XGBClassifier, plot_importance, cv\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.metrics import accuracy_score, hamming_loss, jaccard_score, multilabel_confusion_matrix, classification_report, ConfusionMatrixDisplay\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n","import wandb\n","pd.set_option('display.max_columns', None)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XcKFL0C3AnUD"},"source":["## **Data Analysis**\n","First we load some of the training data and check the first few rows."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"ZEYW4xziOqSq"},"outputs":[],"source":["data_path = '../data/kaggle-eeg/train'\n","features = pd.read_csv(f'{data_path}/subj1_series1_data.csv')\n","labels = pd.read_csv(f'{data_path}/subj1_series1_events.csv')\n","features = features.drop(columns=['id'])\n","labels = labels.drop(columns=['id'])\n","\n","display(features.info(), features.describe(), features.head(), labels.info(), labels.describe(), labels.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_series_data(subject, series):\n","    features = pd.read_csv(f'{data_path}/subj{subject}_series{series}_data.csv')\n","    labels = pd.read_csv(f'{data_path}/subj{subject}_series{series}_events.csv')\n","    return features, labels\n","\n","features, labels = load_series_data(1, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["corr = features.drop(columns=['id']).corr()\n","plt.figure(figsize=(30, 20))\n","sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4V1PII80TV62"},"source":["## **Modeling**"]},{"cell_type":"markdown","metadata":{},"source":["### **Data Preprocessing**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def merge_labels(features, labels):\n","    data = features.copy()\n","    data = data.merge(labels, on='id')\n","    data.drop(columns=['id'], inplace=True)\n","    return data\n","\n","def get_training_batch(series):\n","    features, labels = load_series_data(1, series)\n","    data = merge_labels(features, labels)\n","    for i in range(2, 13):\n","        features, labels = load_series_data(i, series)\n","        data = pd.concat([data, merge_labels(features, labels)])\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df = get_training_batch(1)\n","train_df.shape, train_df.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labels = train_df[['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']]\n","unique_label_combinations, counts = np.unique(labels, axis=0, return_counts=True)\n","\n","plt.figure(figsize=(30, 10))\n","sns.barplot(x=range(len(unique_label_combinations)), y=counts, order=np.argsort(counts)[::-1])\n","plt.title('Label Frequency')\n","plt.xticks(range(len(unique_label_combinations)), unique_label_combinations, rotation=45)\n","plt.xlabel('Label Combination')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# reshape data for CSP\n","def reshape_data(data):\n","    X = data.drop(columns=['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']).values\n","    y = data[['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff', 'Replace', 'BothReleased']].values\n","    y = y.astype(np.float64)\n","    X = np.expand_dims(X, axis=2)\n","    X = X.astype(np.float64)\n","    return X, y\n","\n","X_train, y_train = reshape_data(train_df)\n","X_train = X_train.astype('float64').copy()\n","X_train.shape, y_train.shape, X_train.dtype, y_train.dtype"]},{"cell_type":"markdown","metadata":{},"source":["### **Model Building**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_model(pipeline, param_grid, X_train, y_train, outer_cv=5, inner_cv=5, scoring='jaccard'):\n","    outer_cv = KFold(n_splits=outer_cv, shuffle=True, random_state=42)\n","    scores = []\n","    best_estimators = [] # Store a list of best estimators for each label\n","    best_scores = [] # Store a list of best scores for each label\n","\n","    for train_index, test_index in outer_cv.split(X_train):\n","        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n","        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n","        \n","        # Initialize list to store best estimators and scores for each label in this outer fold\n","        fold_best_estimators = []\n","        fold_best_scores = []\n","\n","        # Iterate over each label (column) in the multi-label target matrix\n","        for label_idx in range(y_train_fold.shape[1]):\n","            y_train_label = y_train_fold[:, label_idx]\n","            y_test_label = y_test_fold[:, label_idx]\n","\n","            inner_cv = KFold(n_splits=inner_cv, shuffle=True, random_state=42)\n","            grid_search = GridSearchCV(pipeline, param_grid, cv=inner_cv, verbose=1, scoring='accuracy', n_jobs=8) # You may change scoring to other suitable multi-label metrics\n","            grid_search.fit(X_train_fold, y_train_label)\n","\n","            y_pred = grid_search.predict(X_test_fold)\n","            \n","            # Example: Calculate multiple metrics\n","            accuracy = accuracy_score(y_test_label, y_pred)\n","            jaccard = jaccard_score(y_test_label, y_pred, average='samples')  \n","            hamming = hamming_loss(y_test_label, y_pred)\n","\n","            scores.append({'accuracy': accuracy, 'jaccard': jaccard, 'hamming': hamming}) \n","            fold_best_estimators.append(grid_search.best_estimator_)\n","            fold_best_scores.append(jaccard)  \n","\n","        best_estimators.append(fold_best_estimators)\n","        best_scores.append(fold_best_scores)\n","        \n","\n","    best_label_indices = []\n","    for scores_per_fold in best_scores:\n","        best_label_indices.append(np.argmax(scores_per_fold))\n","\n","    best_estimators_final = []\n","    for i in range(len(best_estimators)):  # Outer fold\n","        best_estimators_final.append(best_estimators[i][best_label_indices[i]])\n","\n","    best_estimator = best_estimators_final[np.argmax([score[scoring] for score in scores])]\n","    return best_estimator, scores\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Random Forest Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = RandomForestClassifier()\n","rf_pipeline = Pipeline([('CSP', CSP(n_components=4)),\n","                     ('RF', clf)])\n","\n","param_grid = {\n","    'CSP__n_components': [2, 4, 6],\n","    'RF__n_estimators': [50, 100, 200],\n","    'RF__max_depth': [3, 5, 7]\n","}\n","\n","best_rf_pipeline, scores= build_model(rf_pipeline, param_grid, X_train, y_train)\n","print(\"Grid search scores: \", scores)\n","rf_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","scores = cross_val_score(best_rf_pipeline, X_train, y_train, cv=rf_cv, scoring='accuracy')\n","print(\"Cross-validation scores: \", scores)\n","print(\"Best RF parameters: \", best_rf_pipeline.get_params())"]},{"cell_type":"markdown","metadata":{},"source":["#### Gradient Boosting Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = GradientBoostingClassifier()\n","gb_pipeline = Pipeline([('CSP', CSP(n_components=4)),\n","                        ('GB', clf)])\n","\n","param_grid = {\n","    'CSP__n_components': [2, 4, 6],\n","    'GB__n_estimators': [50, 100, 200],\n","    'GB__max_depth': [3, 5, 7]\n","}\n","\n","best_gb_pipeline, scores = build_model(gb_pipeline, param_grid, X_train, y_train)\n","print(\"Grid search scores: \", scores)\n","gb_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","scores = cross_val_score(best_gb_pipeline, X_train, y_train, cv=gb_cv, scoring='accuracy')\n","print(\"Cross-validation scores: \", scores)\n","print(\"Best GB parameters: \", best_gb_pipeline.get_params())"]},{"cell_type":"markdown","metadata":{},"source":["#### XGBoost Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = MultiOutputClassifier(XGBClassifier(), n_jobs=8)\n","xgb_pipeline = Pipeline([('CSP', CSP(n_components=4)), \n","                        ('XGB', clf)])\n","\n","param_grid = {\n","    'CSP__n_components': [2, 4, 6],\n","    'XGB__estimator__n_estimators': [50, 100, 200],\n","    'XGB__estimator__max_depth': [3, 5, 7],\n","    'XGB__estimator__learning_rate': [0.01, 0.1, 0.3],\n","    'XGB__estimator__gamma': [0, 0.1, 0.3],\n","    'XGB__estimator__subsample': [0.5, 0.7, 1],\n","    'XGB__estimator__colsample_bytree': [0.5, 0.7, 1],\n","    'XGB__estimator__reg_alpha': [0, 0.1, 0.3],\n","    'XGB__estimator__reg_lambda': [0, 0.1, 0.3],\n","    'XGB__estimator__eta': [0.01, 0.1, 0.3],\n","}\n","\n","best_xgb_pipeline, scores = build_model(xgb_pipeline, param_grid, X_train, y_train)\n","print(\"Grid search scores: \", scores)\n","xgb_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","scores = cross_val_score(best_xgb_pipeline, X_train, y_train, cv=xgb_cv, scoring='accuracy')\n","print(\"Cross-validation scores: \", scores)\n","print(\"Best XGB parameters: \", best_xgb_pipeline.get_params())"]},{"cell_type":"markdown","metadata":{},"source":["### **Training Loop**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def training_loop(model):\n","    total_test_x = pd.DataFrame()\n","    total_test_y = pd.DataFrame()\n","    for series in range(1, 9):\n","        train_df = get_training_batch(series)\n","        X_train, y_train = reshape_data(train_df)\n","        train_x, test_x, train_y, test_y = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","        model.fit(train_x, train_y)\n","        total_test_x = pd.concat([total_test_x, test_x])\n","        total_test_y = pd.concat([total_test_y, test_y])\n","        score = accuracy_score(total_test_y, model.predict(total_test_x))\n","        print(f\"Series {series} score: {score}\")\n","    y_pred = model.predict(total_test_x)\n","    accuracy = accuracy_score(total_test_y, y_pred)\n","    report = classification_report(total_test_y, y_pred)\n","    return accuracy, report, multilabel_confusion_matrix(total_test_y, y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["### **Training and Evaluation**"]},{"cell_type":"markdown","metadata":{},"source":["#### Random Forest Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rf_accuracy, rf_report, rf_confusion_matrix = training_loop(best_rf_pipeline)\n","print(f\"Random Forest accuracy: {rf_accuracy}\")\n","print(rf_report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(30, 10))\n","\n","ConfusionMatrixDisplay(rf_confusion_matrix[0]).plot(ax=ax[0])\n","estimator = best_rf_pipeline.named_steps['RF']\n","importances = estimator.feature_importances_\n","sns.barplot(x=range(len(importances)), y=importances, ax=ax[1])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Gradient Boosting Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gb_accuracy, gb_report, gb_confusion_matrix = training_loop(best_gb_pipeline)\n","print(f\"Gradient Boosting accuracy: {gb_accuracy}\")\n","print(gb_report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(30, 10))\n","\n","ConfusionMatrixDisplay(gb_confusion_matrix[0]).plot(ax=ax[0])\n","estimator = best_gb_pipeline.named_steps['GB']\n","importances = estimator.feature_importances_\n","sns.barplot(x=range(len(importances)), y=importances, ax=ax[1])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### XGBoost Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["xgb_accuracy, xgb_report, xgb_confusion_matrix = training_loop(best_xgb_pipeline)\n","print(f\"XGBoost accuracy: {xgb_accuracy}\")\n","print(xgb_report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(30, 10))\n","\n","ConfusionMatrixDisplay(xgb_confusion_matrix[0]).plot(ax=ax[0])\n","estimator = best_xgb_pipeline.named_steps['XGB']\n","plot_importance(estimator, ax=ax[1])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2K--Jt6182Ze"},"source":["## **Submission**\n","We're gonna download the testing data now from the Kaggle competition and unzip into the data directory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Mcw0qbEpqkjI"},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -f test.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"uF-4ZsA3Ia_C"},"outputs":[],"source":["!unzip ../data/kaggle-eeg/test.zip -d ../data/kaggle-eeg"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RDLUFWKonI0l"},"source":["Here we load the sample submission from the Kaggle competition. This gives us a pre-made dataframe and we just need to update column values with predictions from our model. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!kaggle competitions download grasp-and-lift-eeg-detection -f sample_submission.csv.zip"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip ../data/kaggle-eeg/sample_submission.csv.zip -d ../data/kaggle-eeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"MPndLKOSVOR5"},"outputs":[],"source":["sub = pd.read_csv('../data/kaggle-eeg/sample_submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":263,"status":"ok","timestamp":1590182742782,"user":{"displayName":"Ralph Dugue","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipnJHGOp2_crugLbpCgfBA1Eg6JMAO-u2DmIQdRg=s64","userId":"10136421352402968883"},"user_tz":240},"id":"uPV2V3mHnPSH","outputId":"0d5eac3c-cf12-4cb8-8e18-5eaeab35d98b"},"outputs":[],"source":["sub.head()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VFNIfCiJ-Edc"},"source":["Here we create a dataframe in the same shape as the example submission on the competition page."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"u5Dic5uwJZS3"},"outputs":[],"source":["path = '../data/kaggle-eeg/test'\n","\n","def get_merged_tests():\n","  tests = None\n","  for sj in range(1, 13):\n","    for sr in range(9, 11):\n","      c_tests = pd.read_csv(f'{path}/subj{sj}_series{sr}_data.csv')\n","      tests = c_tests if tests is None else pd.concat([tests, c_tests])\n","  return tests"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"pL6TXJ-Th65c"},"outputs":[],"source":["tests = get_merged_tests()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"Og5BNjrQmsY4"},"outputs":[],"source":["tests = tests.drop(columns=['id'])\n","tests.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"dI8MZByMhTm-"},"outputs":[],"source":["def get_predictions(model):\n","    data = tests.values\n","    data = np.expand_dims(data, axis=2)\n","    data = data.astype('float64')\n","    return model.predict(data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_predictions_rf = get_predictions(best_rf_pipeline)\n","test_predictions_gb = get_predictions(best_gb_pipeline)\n","test_predictions_xgb = get_predictions(best_xgb_pipeline)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_submission(predictions, message):\n","    sub.iloc[:, 1:] = predictions\n","    sub.to_csv('../data/kaggl-eeg/submission.csv', index=False)\n","    submit_cmd = f'!kaggle competitions submit grasp-and-lift-eeg-detection -f ../data/kaggle-eeg/submission.csv -m \"{message}\"'\n","    !{submit_cmd}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNJ8aQh8YOJPg7rgKkhVC82","name":"EEG Keras","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
